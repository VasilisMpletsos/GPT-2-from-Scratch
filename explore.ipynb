{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "140e8294",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt import GPT2\n",
    "from transformers import AutoTokenizer\n",
    "import torch\n",
    "from torch.functional import F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f3ddd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = GPT2()\n",
    "model = GPT2.load_weights_from_pretrained(\"gpt2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"openai-community/gpt2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daba86c9",
   "metadata": {},
   "source": [
    "## Generate Random output after loading weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "33ef3a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"Hello i am Vasileios Mpletsos an Electrical & Computer Engineer working on AI and ML \"\n",
    "encoded_text = tokenizer.encode(input, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4ace0c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_return_sequences = 5\n",
    "max_length = 30\n",
    "model.eval()\n",
    "model.to(\"cuda\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d83603e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_text = encoded_text.repeat(num_return_sequences,1)\n",
    "encoded_text = encoded_text.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "541cda45",
   "metadata": {},
   "outputs": [],
   "source": [
    "while encoded_text.size(1) < max_length:\n",
    "    with torch.no_grad():\n",
    "        logits = model(encoded_text)\n",
    "        logits = logits[:, -1, :]\n",
    "        probs = F.softmax(logits, dim=-1)\n",
    "        \n",
    "        topk_probs, topk_indices = torch.topk(probs, 20, dim=-1)\n",
    "        selected_tokens = torch.multinomial(topk_probs,1)\n",
    "        selected_tokens = torch.gather(topk_indices,-1,selected_tokens)\n",
    "        encoded_text = torch.cat([encoded_text, selected_tokens], dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ed16a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 30])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ef27a6ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Option 1: Hello i am Vasileios Mpletsos an Electrical & Computer Engineer working on AI and ML  inflamm LionsGYï¿½ GreenpeaceFAQcemberphys devise Plains\n",
      "Option 2: Hello i am Vasileios Mpletsos an Electrical & Computer Engineer working on AI and ML !?\" Dhabi woo sacrificed Canterbury Coinbase abrelevant politely videog\n",
      "Option 3: Hello i am Vasileios Mpletsos an Electrical & Computer Engineer working on AI and ML  Putin facets Gron PCIe borders Burgess exploitation caramel Ladies reborn\n",
      "Option 4: Hello i am Vasileios Mpletsos an Electrical & Computer Engineer working on AI and ML  PutinPLIC specializing Sauce medi trained conservation assail invent reborn\n",
      "Option 5: Hello i am Vasileios Mpletsos an Electrical & Computer Engineer working on AI and ML  layer GPUsidered seizeFX nut colleges Laksh female acclaim\n"
     ]
    }
   ],
   "source": [
    "for i,prediction in enumerate(encoded_text):\n",
    "    decoded_generation = tokenizer.decode(prediction).strip()\n",
    "    print(f\"Option {i+1}: {decoded_generation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d8f3b8",
   "metadata": {},
   "source": [
    "## Check training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b60733c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./tiny_shakespeare.txt\", \"r\") as f:\n",
    "    text = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "28c5966a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Citizen:\n",
      "Before we proceed any further, hear me speak.\n",
      "\n",
      "All:\n",
      "Speak, speak.\n",
      "\n",
      "First Citizen:\n",
      "You are all resolved rather to die than to famish?\n",
      "\n",
      "All:\n",
      "Resolved. resolved.\n",
      "\n",
      "First Citizen:\n",
      "First, you know Caius Marcius is chief enemy to the people.\n",
      "\n",
      "All:\n",
      "We know't, we know't.\n",
      "\n",
      "First Citizen:\n",
      "Let us kill him, and we'll have corn at our own price.\n",
      "Is't a verdict?\n",
      "\n",
      "All:\n",
      "No more talking on't; let it \n"
     ]
    }
   ],
   "source": [
    "print(text[:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf39c50a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "awesome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
